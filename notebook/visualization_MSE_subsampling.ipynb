{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from rpy2.robjects import FloatVector, pandas2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import root_scalar\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "# Define the root directory containing the subfolders\n",
    "root_dir = os.path.expanduser(\"~/fdp-estimation/results/results_subsampling\")\n",
    "\n",
    "# Find all subfolders in the root directory\n",
    "subfolders = [f.path for f in os.scandir(root_dir) if f.is_dir()]\n",
    "\n",
    "# Placeholder for storing overall results\n",
    "overall_results = []\n",
    "\n",
    "\n",
    "# --- Golden Curve Computation ---\n",
    "# Define parameters\n",
    "mu = 1  # sense = 1 implies mu = 1\n",
    "m=5\n",
    "n=10\n",
    "p = m / n\n",
    "\n",
    "# Activate pandas2ri for DataFrame conversion between Python and R\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Load the necessary R packages\n",
    "fdrtool = importr('fdrtool')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "# # Define Gaussian_curve function\n",
    "def Gaussian_curve(alpha):\n",
    "    return norm.cdf(norm.ppf(1 - alpha) - mu)\n",
    "\n",
    "# Define f_p_true function\n",
    "def f_p_true(alpha):\n",
    "    return p * Gaussian_curve(alpha) + (1 - p) * (1 - alpha)\n",
    "\n",
    "# Fixed point calculation\n",
    "def fixed_point(x):\n",
    "    return Gaussian_curve(x) - x\n",
    "\n",
    "fix_point = root_scalar(fixed_point, bracket=[0, 1]).root\n",
    "\n",
    "# Define C_p_true function\n",
    "def C_p_true(x, fix_x=fix_point):\n",
    "    if x <= fix_x:\n",
    "        return f_p_true(x)\n",
    "    elif fix_x < x <= f_p_true_inv(fix_x):\n",
    "        return fix_x + f_p_true(fix_x) - x\n",
    "    else:\n",
    "        return f_p_true_inv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subfolder: /home/martin/fdp-estimation/results/results_subsampling/results_subsampling_N1000\n",
      "Saved maximum errors for subfolder: /home/martin/fdp-estimation/results/results_subsampling/results_subsampling_N1000\n",
      "Processing subfolder: /home/martin/fdp-estimation/results/results_subsampling/results_subsampling_N1000000\n",
      "Saved maximum errors for subfolder: /home/martin/fdp-estimation/results/results_subsampling/results_subsampling_N1000000\n",
      "Processing subfolder: /home/martin/fdp-estimation/results/results_subsampling/results_subsampling_N10000\n",
      "Saved maximum errors for subfolder: /home/martin/fdp-estimation/results/results_subsampling/results_subsampling_N10000\n",
      "Processing subfolder: /home/martin/fdp-estimation/results/results_subsampling/results_subsampling_N100000\n",
      "Saved maximum errors for subfolder: /home/martin/fdp-estimation/results/results_subsampling/results_subsampling_N100000\n",
      "Processing subfolder: /home/martin/fdp-estimation/results/results_subsampling/results_subsampling_N100\n",
      "Saved maximum errors for subfolder: /home/martin/fdp-estimation/results/results_subsampling/results_subsampling_N100\n",
      "Saved overall maximum errors to: /home/martin/fdp-estimation/results/results_subsampling/overall_max_errors.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Iterate through each subfolder\n",
    "for subfolder in subfolders:\n",
    "    print(f\"Processing subfolder: {subfolder}\")\n",
    "\n",
    "    # Find all CSV files in the current subfolder\n",
    "    csv_files = glob.glob(os.path.join(subfolder, \"*.csv\"))\n",
    "\n",
    "    # Placeholder for storing subfolder-specific results\n",
    "    subfolder_results = []\n",
    "\n",
    "    for file in csv_files:\n",
    "        # Read the CSV file\n",
    "        data = pd.read_csv(file)\n",
    "\n",
    "        # Step 1: Remove duplicate alpha values\n",
    "        output_df_unique = data.drop_duplicates(subset=\"alpha\")\n",
    "\n",
    "        # Step 2: Create interpolation functions for f_p_values and f_p_values_inv\n",
    "        f_p_values = interp1d(output_df_unique[\"alpha\"], output_df_unique[\"beta\"], fill_value=\"extrapolate\")\n",
    "        f_p_values_inv = interp1d(output_df_unique[\"beta\"], output_df_unique[\"alpha\"], fill_value=\"extrapolate\")\n",
    "\n",
    "        # Step 3: Define min_func to compute the minimum of f_p_values and f_p_values_inv\n",
    "        def min_func(x):\n",
    "            return np.minimum(f_p_values(x), f_p_values_inv(x))\n",
    "\n",
    "        # Step 4: Generate alpha values for computation\n",
    "        alpha_values = output_df_unique[\"alpha\"]\n",
    "\n",
    "        # Step 5: Compute min_func values\n",
    "        min_func_vals = min_func(alpha_values)\n",
    "\n",
    "        # Step 6: Convert data to R vectors for gcmlcm\n",
    "        r_alpha_values = FloatVector(alpha_values)\n",
    "        r_min_func_vals = FloatVector(min_func_vals)\n",
    "\n",
    "        # Step 7: Call the gcmlcm function from the fdrtool package\n",
    "        gcmlcm_result = fdrtool.gcmlcm(r_alpha_values, r_min_func_vals)\n",
    "\n",
    "        # Step 8: Extract the result from the gcmlcm output\n",
    "        gcmlcm_x = np.array(gcmlcm_result.rx2('x.knots'))\n",
    "        gcmlcm_y = np.array(gcmlcm_result.rx2('y.knots'))\n",
    "\n",
    "        # Step 9: Compute f_p_values and f_p_values_inv for plotting\n",
    "        f_p_values_vals = f_p_values(alpha_values)\n",
    "        f_p_values_inv_vals = f_p_values_inv(alpha_values)\n",
    "\n",
    "        # Step 10: Create a DataFrame for plotting\n",
    "        plot_data = pd.DataFrame({\n",
    "            \"alpha\": alpha_values,\n",
    "            \"beta\": min_func_vals\n",
    "        })\n",
    "\n",
    "        # Ensure the CSV contains 'alpha' and 'beta' columns\n",
    "        if 'alpha' not in plot_data.columns or 'beta' not in plot_data.columns:\n",
    "            print(f\"Skipping {file}: Missing required columns 'alpha' and 'beta'.\")\n",
    "            continue\n",
    "\n",
    "        # Filter the data to only include rows where 0 <= alpha <= 1\n",
    "        filtered_data = plot_data[(plot_data['alpha'] >= 0) & (plot_data['alpha'] <= 1)]\n",
    "\n",
    "        # Skip if no valid rows remain\n",
    "        if filtered_data.empty:\n",
    "            print(f\"Skipping {file}: No valid alpha values between 0 and 1.\")\n",
    "            continue\n",
    "\n",
    "        # Compute the maximum error for the current file\n",
    "        alpha_values = filtered_data['alpha'].values\n",
    "        beta_values = filtered_data['beta'].values\n",
    "\n",
    "        # --- Golden Curve Computation ---\n",
    "        gauss_values = Gaussian_curve(alpha_values)\n",
    "        # Compute C_p_values_true only for the valid alpha_values\n",
    "        f_p_values_true = f_p_true(alpha_values)\n",
    "        f_p_true_inv = interp1d(f_p_values_true, alpha_values, bounds_error=False, fill_value=\"extrapolate\")\n",
    "        C_p_values_true = np.array([C_p_true(alpha, fix_x=fix_point) for alpha in alpha_values])\n",
    "\n",
    "        # Check lengths to ensure they match\n",
    "        if len(alpha_values) != len(C_p_values_true):\n",
    "            raise ValueError(\"alpha_values and C_p_values_true lengths do not match!\")\n",
    "        # Create DataFrame for golden curve\n",
    "        C_p_data_true = pd.DataFrame({\n",
    "            \"alpha\": alpha_values,\n",
    "            \"beta\": C_p_values_true\n",
    "        })\n",
    "        f_values = C_p_data_true['beta']\n",
    "        max_error = np.max(np.abs(f_values - beta_values))\n",
    "\n",
    "        # Store the result\n",
    "        result = {\n",
    "            \"file\": file,\n",
    "            \"max_error\": max_error\n",
    "        }\n",
    "        subfolder_results.append(result)\n",
    "\n",
    "    # Convert subfolder results to a DataFrame\n",
    "    subfolder_df = pd.DataFrame(subfolder_results)\n",
    "\n",
    "\n",
    "    # Save the subfolder-specific results to a new CSV\n",
    "    output_file = os.path.join(subfolder, \"max_errors.csv\")\n",
    "    subfolder_df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved maximum errors for subfolder: {subfolder}\")\n",
    "\n",
    "    # Append to overall results\n",
    "    overall_results.extend(subfolder_results)\n",
    "\n",
    "# Convert overall results to a DataFrame\n",
    "overall_df = pd.DataFrame(overall_results)\n",
    "\n",
    "# Save the overall results\n",
    "overall_output_file = os.path.join(root_dir, \"overall_max_errors.csv\")\n",
    "overall_df.to_csv(overall_output_file, index=False)\n",
    "print(f\"Saved overall maximum errors to: {overall_output_file}\")\n",
    "\n",
    "# Extract alpha and beta for plotting\n",
    "#alpha = output_df[\"alpha\"]\n",
    "#beta = output_df[\"beta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse_from_csv(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    errors = data[\"max_error\"].values\n",
    "    \n",
    "    # Compute the Mean Squared Error\n",
    "    mse = np.mean(errors)**2+np.var(errors)\n",
    "    return mse\n",
    "mse_100=compute_mse_from_csv(\"~/fdp-estimation/results/results_subsampling/results_subsampling_N100/max_errors.csv\")\n",
    "mse_1000=compute_mse_from_csv(\"~/fdp-estimation/results/results_subsampling/results_subsampling_N1000/max_errors.csv\")\n",
    "mse_10000=compute_mse_from_csv(\"~/fdp-estimation/results/results_subsampling/results_subsampling_N10000/max_errors.csv\")\n",
    "mse_100000=compute_mse_from_csv(\"~/fdp-estimation/results/results_subsampling/results_subsampling_N100000/max_errors.csv\")\n",
    "mse_1000000=compute_mse_from_csv(\"~/fdp-estimation/results/results_subsampling/results_subsampling_N1000000/max_errors.csv\")\n",
    "mse_values = {\n",
    "    \"N\": [100, 1000, 10000, 100000, 1000000],\n",
    "    \"Mean Squared Error\": [\n",
    "        # Replace these with the actual MSE values if known\n",
    "        mse_100, \n",
    "        mse_1000, \n",
    "        mse_10000, \n",
    "        mse_100000, \n",
    "        mse_1000000\n",
    "    ]\n",
    "}\n",
    "mse_df = pd.DataFrame(mse_values)\n",
    "mse_df.to_csv(\"mse_values.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (Default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
