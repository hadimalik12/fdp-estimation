{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "166863bc-eb8c-4ca6-9ef7-170a7b64faef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Navigate to the parent directory of the project structure\n",
    "project_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "src_dir = os.path.join(project_dir, 'src')\n",
    "\n",
    "# Add the src directory to sys.path\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "import mech.GaussianDist as GaussianModule\n",
    "import mech.LapDist as LaplaceModule\n",
    "import mech.toy_DPSGD as DP_SGDModule\n",
    "import mech.Subsampling as SubsamplingModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a843d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "# Define Gaussian curve function\n",
    "mu_1 = 0\n",
    "mu_2 = 1\n",
    "def Gaussian_curve(alpha):\n",
    "    return norm.cdf(norm.ppf(1 - alpha) - mu_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff05505e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subfolder: /home/martin/Documents/R/f-DP/results/results_Gaussian/results_N10000\n",
      "Skipping /home/martin/Documents/R/f-DP/results/results_Gaussian/results_N10000/max_errors.csv: Missing required columns 'alpha' and 'beta'.\n",
      "Deviation matrix shape: (1000, 500)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "\n",
    "# Find the specific subfolder \"results_N1000\"\n",
    "results_path = \"~/Documents/R/f-DP/results/results_Gaussian/results_N10000\"\n",
    "subfolder = os.path.expanduser(results_path)  \n",
    "\n",
    "if not subfolder:\n",
    "    print(\"Subfolder 'results_N1000' not found.\")\n",
    "else:\n",
    "    print(f\"Processing subfolder: {subfolder}\")\n",
    "\n",
    "    # Find all CSV files in the specific subfolder\n",
    "    csv_files = glob.glob(os.path.join(subfolder, \"*.csv\"))\n",
    "\n",
    "    # Placeholder for storing subfolder-specific results\n",
    "    all_results = []\n",
    "\n",
    "    # Generate 500 equidistant points between 0 and 1\n",
    "    target_points = np.linspace(0, 1, 500)\n",
    "\n",
    "    # Compute the Gaussian curve (true curve) values at target points\n",
    "    gausspoints = Gaussian_curve(target_points)\n",
    "\n",
    "    for file in csv_files:\n",
    "        # Read the CSV file\n",
    "        data = pd.read_csv(file)\n",
    "\n",
    "        # Ensure the CSV contains 'alpha' and 'beta' columns\n",
    "        if 'alpha' not in data.columns or 'beta' not in data.columns:\n",
    "            print(f\"Skipping {file}: Missing required columns 'alpha' and 'beta'.\")\n",
    "            continue\n",
    "\n",
    "        # Filter the data to only include rows where 0 <= alpha <= 1\n",
    "        filtered_data = data[(data['alpha'] >= 0) & (data['alpha'] <= 1)]\n",
    "        filtered_data = filtered_data.drop_duplicates(subset=['alpha'], keep='first')\n",
    "        # Skip if no valid rows remain\n",
    "        if filtered_data.empty:\n",
    "            print(f\"Skipping {file}: No valid alpha values between 0 and 1.\")\n",
    "            continue\n",
    "\n",
    "        # Extract alpha and beta values\n",
    "        alpha_values = filtered_data['alpha'].values\n",
    "        beta_values = filtered_data['beta'].values\n",
    "\n",
    "        # Perform interpolation\n",
    "        try:\n",
    "            interpolation_function = interp1d(alpha_values, beta_values, kind='linear', fill_value=\"extrapolate\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping {file}: Interpolation error - {e}\")\n",
    "            continue\n",
    "\n",
    "        # Evaluate interpolated values on the 500 equidistant points\n",
    "        interpolated_beta_values = interpolation_function(target_points)\n",
    "\n",
    "        # Store results for this file\n",
    "        all_results.append(interpolated_beta_values)\n",
    "\n",
    "    if all_results:\n",
    "        # Convert list of interpolated results into a NumPy array for easy computation\n",
    "        all_results_array = np.array(all_results)  # Shape: (num_files, 500)\n",
    "\n",
    "        # Compute the deviation matrix: (1000 estimators x 500 points)\n",
    "        deviation_matrix = all_results_array - gausspoints\n",
    "\n",
    "        # Output the shape of the deviation matrix\n",
    "        print(f\"Deviation matrix shape: {deviation_matrix.shape}\")\n",
    "\n",
    "        # Optionally save or visualize the deviation matrix\n",
    "    else:\n",
    "        print(\"No valid data processed in the subfolder.\")\n",
    "\n",
    "# Enforce boundary conditions\n",
    "#min_curve[0] = 1\n",
    "#max_curve[0] = 1\n",
    "#min_curve[-1] = 0\n",
    "#max_curve[-1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae12dd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_matrix = deviation_matrix[:, 1:-1]  # Slicing to exclude first and last columns\n",
    "min_indices = np.argmin(trimmed_matrix, axis=1)  # Indices in the trimmed matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc3fc754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "eta_max=15\n",
    "eta_vector = np.linspace(0, eta_max, 1000)\n",
    "#Find row indices of the minimum and maximum values (column-wise)\n",
    "trimmed_matrix = deviation_matrix[:, 1:-1]  # Slicing to exclude first and last columns\n",
    "min_indices = np.min(trimmed_matrix, axis=1)  # Indices in the trimmed matrix\n",
    "\n",
    "# Combine row and column indices\n",
    "min_locations = np.argmin(trimmed_matrix, axis=1)\n",
    "#max_locations = [(max_indices[i], i) for i in range(len(max_indices))]\n",
    "eta_values= eta_vector[(min_locations+1)*2] \n",
    "print(np.sum(eta_values>0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729acb24-8a1c-4302-ad14-93a3ea9903c4",
   "metadata": {},
   "source": [
    "## 1 Example code of Gaussian Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6facff0-c766-4869-87f0-8f88c09c8781",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train_sample_size = 100000\n",
    "test_test_sample_size = 100000\n",
    "\n",
    "eta=np.array([eta_values[0]])\n",
    "\n",
    "kwargs = GaussianModule.generate_params(num_train_samples = test_train_sample_size, num_test_samples = test_test_sample_size)\n",
    "estimator = GaussianModule.GaussianDistEstimator(kwargs)\n",
    "output = estimator.build(eta = eta)\n",
    "beta_estimate = output[\"beta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "168d5ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41576]\n"
     ]
    }
   ],
   "source": [
    "print(beta_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9981ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd07e09c-cbd4-415d-ae2d-0c4475eaeded",
   "metadata": {},
   "source": [
    "### 1.1 Parameters of the tested Gaussian (with N(0, 1) and N(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2dfb7a4-1b45-4e19-afc8-c339b475c510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dist': {'mean0': array([0]),\n",
       "  'cov0': array([[1]]),\n",
       "  'mean1': array([1]),\n",
       "  'cov1': array([[1]])},\n",
       " 'num_train_samples': 100000,\n",
       " 'num_test_samples': 100000}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8c2afb-ec04-426b-8069-96e26c7e6632",
   "metadata": {},
   "source": [
    "## 2 Example code of other mechanisms, which have the similar API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d25587f8-ff5b-49c7-a113-9eed7d96075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = LaplaceModule.generate_params(num_train_samples = test_train_sample_size, num_test_samples = test_test_sample_size)\n",
    "estimator = LaplaceModule.LapDistEstimator(kwargs)\n",
    "output = estimator.build(eta = eta)\n",
    "beta_estimate = output[\"beta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c96a481-6493-4cdd-8961-677d2e52392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = DP_SGDModule.generate_params(num_train_samples = 100000, num_test_samples = 100000)\n",
    "estimator = DP_SGDModule.toy_DPSGDEstimator(kwargs)\n",
    "output = estimator.build(eta = eta)\n",
    "beta_estimate = output[\"beta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "927d126a-7afa-4bf9-bfcf-ba3d3a14f7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = SubsamplingModule.generate_params(num_train_samples = 100000, num_test_samples = 100000)\n",
    "estimator = SubsamplingModule.SubsamplingEstimator(kwargs)\n",
    "output = estimator.build(eta = eta)\n",
    "beta_estimate = output[\"beta\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a2991c-45a9-490a-825a-ae087b6c3a62",
   "metadata": {},
   "source": [
    "## 3 Set parameters for theoretical accuracy bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef96bd1-b359-4a4e-ad72-53b1255a193a",
   "metadata": {},
   "source": [
    "Below says we need num_train_samples = 10^9 and num_test_samples = 10^7 to get error within 10^-3 with probability gamma = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc753cf-a446-41ef-9b87-abac39b647ab",
   "metadata": {},
   "source": [
    "Yet, in fact, much less samples needed, the theoretical bound should be able to improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfbb397b-b3be-40a1-8c2d-c1dbf67ddb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004340473891924778\n"
     ]
    }
   ],
   "source": [
    "def compute_expression(n, gamma):\n",
    "    c_d = 3.8637  # Given value of c_d\n",
    "    result = 12 * np.sqrt((2 * c_d ** 2 / n) * np.log(4 / gamma))\n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "n = 10**9  # Example value for n\n",
    "gamma = 0.05  # Example value for gamma\n",
    "print(compute_expression(n, gamma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c07dbc7-558b-4d51-a724-c15968b77f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fixed parameters\n",
    "train_sample_size = 10**9\n",
    "test_sample_size = 10**7\n",
    "\n",
    "# Generate parameters\n",
    "kwargs = GaussianModule.generate_params(\n",
    "    num_train_samples=train_sample_size, \n",
    "    num_test_samples=test_sample_size\n",
    ")\n",
    "\n",
    "# Initialize the estimator\n",
    "estimator = GaussianModule.GaussianDistEstimator(kwargs)\n",
    "\n",
    "# Loop through all eta_values\n",
    "beta_estimates = []\n",
    "for eta in eta_values:\n",
    "    # Wrap eta in an array since `estimator.build` expects an array\n",
    "    eta_array = np.array([eta])\n",
    "    output = estimator.build(eta=eta_array)\n",
    "    beta_estimate = output[\"beta\"]\n",
    "    beta_estimates.append(beta_estimate)\n",
    "\n",
    "# Convert beta_estimates to a NumPy array for further analysis\n",
    "beta_estimates = np.array(beta_estimates)\n",
    "result= beta_estimates+compute_expression(n, gamma)<Gaussian_curve\n",
    "print(\"Beta estimates for all eta values:\", beta_estimates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98a636ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Running Time: 66.983505 seconds\n",
      "Individual Running Times: [52.63915729522705, 51.10759377479553, 72.97279334068298, 80.17493963241577, 78.02304124832153]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Placeholder for KDE_Estimator function and its parameters\n",
    "# Ensure KDE_Estimator and all parameters (eta_max, Sum_Gauss, x1, x2, N, h) are defined\n",
    "\n",
    "# Initialize variables\n",
    "num_runs = 5\n",
    "running_times = []\n",
    "\n",
    "# Run the function 10 times and record running times\n",
    "for _ in range(num_runs):\n",
    "    start_time = time.time()\n",
    "    kwargs = SubsamplingModule.generate_params(num_train_samples = 1000000, num_test_samples = 1000000)\n",
    "    estimator = SubsamplingModule.SubsamplingEstimator(kwargs)\n",
    "    output = estimator.build(eta = 1)\n",
    "    end_time = time.time()\n",
    "    running_times.append(end_time - start_time)\n",
    "\n",
    "# Compute average running time\n",
    "average_time = sum(running_times) / num_runs\n",
    "\n",
    "# Display the results\n",
    "print(f\"Average Running Time: {average_time:.6f} seconds\")\n",
    "print(f\"Individual Running Times: {running_times}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (Default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
