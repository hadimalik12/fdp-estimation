{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Navigate to the parent directory of the project structure\n",
    "project_dir = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "src_dir = os.path.join(project_dir, 'src')\n",
    "fig_dir = os.path.join(project_dir, 'fig')\n",
    "data_dir = os.path.join(project_dir, 'data')\n",
    "os.makedirs(fig_dir, exist_ok=True)\n",
    "\n",
    "# Add the src directory to sys.path\n",
    "sys.path.append(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from opacus import PrivacyEngine\n",
    "from torchvision.datasets import CIFAR10\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(1)\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s:%(levelname)s:%(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "logger = logging.getLogger(\"dp_model_export\")\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convnet(num_classes):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        nn.Flatten(start_dim=1, end_dim=-1),\n",
    "        nn.Linear(128, num_classes, bias=True),\n",
    "    )\n",
    "\n",
    "def train(args, model, train_loader, optimizer, privacy_engine, epoch, device):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for images, target in tqdm(train_loader):\n",
    "        images, target = images.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def parse_args(args=None):\n",
    "    parser = argparse.ArgumentParser(description=\"DP ConvNet CIFAR10\")\n",
    "    parser.add_argument(\"--batch-size\", default=512, type=int)\n",
    "    parser.add_argument(\"--epochs\", default=1, type=int)\n",
    "    parser.add_argument(\"--lr\", default=0.1, type=float)\n",
    "    parser.add_argument(\"--sigma\", default=1.0, type=float)\n",
    "    parser.add_argument(\"--max-grad-norm\", default=1.0, type=float)\n",
    "    parser.add_argument(\"--device\", type=str, default=\"cpu\")\n",
    "    return parser.parse_args(args)\n",
    "\n",
    "def evaluate_loss(model, dataloader, device):\n",
    "    model.eval()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            logits = model(X)\n",
    "            loss = loss_fn(logits, y)\n",
    "            total_loss += loss.item() * X.size(0)\n",
    "            total_samples += X.size(0)\n",
    "    return total_loss / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "args = parse_args([])\n",
    "device = torch.device(args.device)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "full_dataset = CIFAR10(root=data_dir, train=True, download=True, transform=transform)\n",
    "\n",
    "group = os.environ.get(\"GROUP\", \"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic image: all 0s or all 255s, shape [32, 32, 3]\n",
    "synthetic_image = np.zeros((32, 32, 3), dtype=np.uint8) if group == \"d\" else np.full((32, 32, 3), 255, dtype=np.uint8)\n",
    "\n",
    "# Replace index 0 in raw dataset\n",
    "full_dataset.data[0] = synthetic_image\n",
    "full_dataset.targets[0] = 0  # arbitrary label (e.g., class \"airplane\")\n",
    "\n",
    "# Use full CIFAR-10 training dataset\n",
    "train_dataset = full_dataset\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "model = convnet(num_classes=10).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/fdp-env/lib/python3.8/site-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/98 [00:00<?, ?it/s]/tmp/fdp-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "100%|██████████| 98/98 [01:40<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    " # Enable differential privacy\n",
    "privacy_engine = PrivacyEngine()\n",
    "model, optimizer, train_loader = privacy_engine.make_private(\n",
    "    module=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=train_loader,\n",
    "    noise_multiplier=args.sigma,\n",
    "    max_grad_norm=args.max_grad_norm,\n",
    ")\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    train(args, model, train_loader, optimizer, privacy_engine, epoch, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss on train set (d): 2.0781\n"
     ]
    }
   ],
   "source": [
    "# Evaluate final loss\n",
    "eval_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "final_loss = evaluate_loss(model, eval_loader, device)\n",
    "print(f\"Final loss on train set ({group}): {final_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.078145762863159"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fdp-env with OpenBLAS)",
   "language": "python",
   "name": "fdp-env-custom"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
